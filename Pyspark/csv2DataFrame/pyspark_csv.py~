# -*- coding: UTF-8 -*-

import csv
import sys
import dateutil.parser
from pyspark.sql.types import (StringType, DoubleType, TimestampType, NullType,
                               IntegerType, StructType, StructField)

py_version = sys.version_info[0]


def csvToDataFrame(sqlCtx, rdd, columns=None, sep=",", parseDate=True):
    """Converts CSV plain text RDD into SparkSQL DataFrame (former SchemaRDD)
    using PySpark. If columns not given, assumes first row is the header.
    If separator not given, assumes comma separated
    """
    if py_version < 3:
        def toRow(line):
            return toRowSep(line.encode('utf-8'), sep)
    else:
        def toRow(line):
            return toRowSep(line, sep)

    rdd_array = rdd.map(toRow) #将每一行的字段拆分，得到的结果是汇总表
    rdd_sql = rdd_array

    if columns is None: #数据集包含表头
        columns = rdd_array.first() # 表的第一行
	#数据集要去除第一行
        rdd_sql = rdd_array.zipWithIndex().filter(
            lambda r_i: r_i[1] > 0).keys()
    #得到每一列数据的字段类型
    column_types = evaluateType(rdd_sql, parseDate)

    # 得到构建DataFrame需要用到的数据
    def toSqlRow(row): # row: rdd_sql的每一行
        return toSqlRowWithType(row, column_types)

    schema = makeSchema(zip(columns, column_types))

    #rdd_sql.map:对rdd_sql中的每一行执行操作
    return sqlCtx.createDataFrame(rdd_sql.map(toSqlRow), schema=schema)


def makeSchema(columns): #columns:zip(columns, column_types)
    struct_field_map = {'string': StringType(),
                        'date': TimestampType(),
                        'double': DoubleType(),
                        'int': IntegerType(),
                        'none': NullType()}
    fields = [StructField(k, struct_field_map[v], True) for k, v in columns]

    return StructType(fields)


def toRowSep(line, d):
    """Parses one row using csv reader"""
    for r in csv.reader([line], delimiter=d):
        return r

"""
  根据每一列数据的类型对数据进行类型转换
  col_types：每一列数据的类型

"""
def toSqlRowWithType(row, col_types):
    """Convert to sql.Row"""
    d = row
    for col, data in enumerate(row):
        typed = col_types[col]
        if isNone(data):
            d[col] = None
        elif typed == 'string':
            d[col] = data
        elif typed == 'int':
            d[col] = int(round(float(data)))
        elif typed == 'double':
            d[col] = float(data)
        elif typed == 'date':
            d[col] = toDate(data)
    return d


# Type converter
def isNone(d):
    return (d is None or d == 'None' or
            d == '?' or
            d == '' or
            d == 'NULL' or
            d == 'null')

"""
  转换成日期类型
"""
def toDate(d):
    return dateutil.parser.parse(d)


"""
  推断每行的数据类型，处理日期类型
"""
def getRowType(row):
    """Infers types for each row"""
    d = row
    for col, data in enumerate(row):
        try:
            if isNone(data):
                d[col] = 'none'
            else:
                num = float(data)
                if num.is_integer():
                    d[col] = 'int'
                else:
                    d[col] = 'double'
        except:
            try:
                toDate(data)
                d[col] = 'date'
            except:
                d[col] = 'string'
    return d

"""
  推断每行的数据类型，不处理日期类型
"""
def getRowTypeNoDate(row):
    """Infers types for each row"""
    d = row
    for col, data in enumerate(row):
        try:
            if isNone(data):
                d[col] = 'none'
            else:
                num = float(data)
                if num.is_integer():
                    d[col] = 'int'
                else:
                    d[col] = 'double'
        except:
            d[col] = 'string'
    # 返回d: ex:['string','string','int'.....]
    return d

"""
  对每一行的数据进行对比，得出最终每一列的数据类型
"""
def reduceTypes(a, b):
    """Reduces column types among rows to find common denominator"""
    type_order = {'string': 0, 'date': 1, 'double': 2, 'int': 3, 'none': 4}
    reduce_map = {'int': {0: 'string', 1: 'string', 2: 'double'},
                  'double': {0: 'string', 1: 'string'},
                  'date': {0: 'string'}}
    # ex:传入的第一个数据：a=['string','string','int'.....] 传入的第二个数据 b=['string','string','int'.....]
    d = a
    for col, a_type in enumerate(a):
        # a_type = a[col]
        b_type = b[col]
        # 当a中的数据为None，b中的数据不为None，返回b的数据类型
        if a_type == 'none':
            d[col] = b_type
	# 当b中的数据为None，a中的数据不为None，返回a的数据类型
        elif b_type == 'none':
            d[col] = a_type
        # 当a与b的数据都不为None
        else:
            order_a = type_order[a_type] #为a的数据类型编号
            order_b = type_order[b_type] #为b的数据类型编号
            if order_a == order_b: #当编号一致，返回a或b的数据类型都可以
                d[col] = a_type
            elif order_a > order_b:
                d[col] = reduce_map[a_type][order_b]
            elif order_a < order_b:
                d[col] = reduce_map[b_type][order_a]
    return d

"""
  评估字段类型
"""
def evaluateType(rdd_sql, parseDate):
    if parseDate:
        return rdd_sql.map(getRowType).reduce(reduceTypes)
    else:
        return rdd_sql.map(getRowTypeNoDate).reduce(reduceTypes)
